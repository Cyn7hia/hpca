**hpca** provides an efficient implementation of the Hellinger PCA for computating word embeddings.
See the [EACL 2014 paper](http://lebret.ch/wp-content/uploads/2014/03/eacl2014.pdf) for more details.

## PREREQUISITES

 This project requires:
  * Cross-platform Make (CMake) v2.6+
  * GNU Make or equivalent.
  * GCC or an alternative, reasonably conformant C++ compiler.
  * Zlib v1.2.5
  * OpenMP API (optional)
  * Doxygen (in order to make documentation which is optional)

## BUILDING
 
 This project uses the Cross-platform Make (CMake) build system. However, we
 have conveniently provided a wrapper configure script and Makefile so that
 the typical build invocation of `./configure` followed by `make` will work.
 For a list of all possible build targets, use the command `make help`.

 **NOTE**: Users of CMake may believe that the top-level Makefile has been
 generated by CMake; it hasn't, so please do not delete that file.

## INSTALLING

 Once the project has been built (see "BUILDING"), execute `sudo make install`.
 See [Install](INSTALL.md) for more details.

## GETTING WORD EMBEDDINGS

This package includes 6 different tools:

### Corpus preprocessing 

Lowercase conversion and/or all numbers replaced with a special token ('0').


The corpus needs to be a **tokenized** plain text file containing only the **sentences** of the corpus.

Before running the `preprocess` tool, authors strongly recommend to follow these two steps:
1.  Running a sentence detector, e.g. [the Apache OpenNLP Sentence Dectector](https://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.sentdetect).
```
./apache-opennlp-1.5.3/bin/opennlp SentenceDetector ./apache-opennlp-1.5.3/bin/en-sent.bin < corpus.txt > corpus-sentences.txt
```
2.  Running a tokenizer, e.g. [the Stanford Tokenizer](http://nlp.stanford.edu/software/tokenizer.shtml).
```
java -cp stanford-parser.jar edu.stanford.nlp.process.PTBTokenizer -preserveLines corpus-sentences.txt > corpus-token.txt
```

`preprocess` options:
* `-lower <int>`: Lowercased? 0 or 1 (default)
* `-digit <int>`: Replace all digits with a special token? 0, 1 (default)
* `-input-file <file>`: Input file to preprocess (gzip format is allowed)
* `-output-file <file>`: Output file to save preprocessed data
* `-gzip <int>`: Save in gzip format? 0 or 1 (default)
* `-threads <int>`: Number of threads; default 8
* `-verbose <int>`: Set verbosity: 0 or 1 (default)
**Example**:
```
preprocess -input-file corpus-token.txt -output-file corpus-clean.txt -lower 1 -digit 1 -verbose 1 -threads 8 -gzip 0
```

## AUTHORS 

 * RÃ©mi Lebret: remi@lebret.ch

## ACKNOWLEDGEMENTS

  * Eigen3 -- http://eigen.tuxfamily.org

  Eigen 3 is a lightweight C++ template library for vector and matrix math, a.k.a. linear algebra.
  

  * redsvd -- https://code.google.com/p/redsvd/

  redsvd is a library for solving several matrix decompositions including singular value decomposition (SVD), principal component analysis (PCA), and eigen value decomposition.
  redsvd uses Eigen3.


